{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01e61b83-6ae8-4db8-80a2-0e5998bd5807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T_local (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function T_local(q,c)\n",
    "    return -1/log(1-(q/(1+sqrt(c-1))))\n",
    "end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f517031d-c4de-4c8b-ae1b-2d7b052e611c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 63.354800 seconds (98.90 M allocations: 2.459 GiB, 0.86% gc time, 1.98% compilation time: 29% of which was recompilation)\n",
      "θ = 0.0 threshold = 0.0\n",
      "M = 5000 N = 50 Meff = 5000\n",
      "θ = 0.0 threshold = 0.0\n",
      "M = 5000 N = 50 Meff = 5000\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `matrix2fasta` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `matrix2fasta` not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[2]:101"
     ]
    }
   ],
   "source": [
    "using Revise, Genie, StatsBase, Statistics, JLD2, DCAUtils, PyPlot\n",
    "\n",
    "using Graphs, Random\n",
    "\n",
    "function generate_random_regular_graph(L, d)\n",
    "    @assert d < n \"Degree must be less than the number of nodes\"\n",
    "    @assert iseven(n * d) \"n*d must be even for a valid d-regular graph\"\n",
    "\n",
    "    edges = Tuple{Int, Int}[]\n",
    "    stubs = repeat(1:n, d)\n",
    "    shuffle!(stubs)\n",
    "\n",
    "    while !isempty(stubs)\n",
    "        u, v = pop!(stubs), pop!(stubs)\n",
    "        if u != v && !((u, v) in edges || (v, u) in edges)\n",
    "            push!(edges, (u, v))\n",
    "        else\n",
    "            push!(stubs, u)\n",
    "            push!(stubs, v)\n",
    "            shuffle!(stubs)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    G = SimpleGraph(n)\n",
    "    for (u, v) in edges\n",
    "        add_edge!(G, u, v)\n",
    "    end\n",
    "    return G\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "L = 50; c = 5; temp = 0.30; q = 4;\n",
    "\n",
    "# Example usage:\n",
    "n, d = 50, 5  # 100 nodes, degree 3\n",
    "coupl = 1.0  # Antiferromagnetic interaction\n",
    "G = generate_random_regular_graph(n, d)\n",
    "connections = [neighbors(G,i) for i in 1:50];\n",
    "J = zeros(q,L,q,L);\n",
    "h = zeros(q,L)\n",
    "for i in 1:L\n",
    "    for j in connections[i]\n",
    "        for a in 1:q\n",
    "            J[a,i,a,j] = -1\n",
    "        end\n",
    "    end \n",
    "end\n",
    "\n",
    "N_steps = 10^5; N_chains = 5000; start_msa = Int8.(rand(1:q,L, N_chains));\n",
    "mean_dist = [];mean_intra_dist = [];mean_t2_dist = []; steps = []; steps_t2 = [];\n",
    "\n",
    "@time res_eq = run_potts(start_msa, \n",
    "        h, \n",
    "        J, \n",
    "        temp = temp,\n",
    "        each_step = 1000,\n",
    "        N_steps = N_steps, \n",
    "        q = q);\n",
    "\n",
    "for n in 1:length(res_eq.steps)  \n",
    "    push!(mean_dist, mean(ham_dist(start_msa, res_eq.step_msa[n])))\n",
    "    push!(mean_intra_dist, pairwise_ham_dist(res_eq.step_msa[n], n_seq = 500))\n",
    "    push!(steps, res_eq.steps[n])\n",
    "    if length(findall(x -> x == ((res_eq.steps[n]-1)/2)+1, res_eq.steps)) == 1\n",
    "        push!(steps_t2, res_eq.steps[n])\n",
    "        ind = findall(x -> x == ((res_eq.steps[n]-1)/2)+1, res_eq.steps)[1]\n",
    "        push!(mean_t2_dist, mean(Genie.ham_dist(res_eq.step_msa[n], res_eq.step_msa[ind]))) \n",
    "    end\n",
    "end\n",
    "\n",
    "close(\"all\"); \n",
    "    plt.plot(steps ./ L, mean_dist ./ L)\n",
    " plt.xscale(\"log\");  plt.xlabel(\"Sweeps\"); plt.ylabel(\"Hamming_from_start\"\n",
    "    ); savefig(\"../ciao_dist.png\")\n",
    "\n",
    "close(\"all\"); \n",
    "    plt.plot(steps ./ L, mean_intra_dist ./ L)\n",
    "    plt.scatter(steps_t2 ./ L, mean_t2_dist ./ L)\n",
    "plt.xscale(\"log\");  plt.xlabel(\"Sweeps\"); plt.ylabel(\"Pairwise Hamming\"\n",
    "    ); savefig(\"../ciao_intra_dist.png\")\n",
    "\n",
    "\n",
    "\n",
    "rand_msa = Int8.(rand(1:q,L, N_chains));\n",
    "f1_0,f2_0 = compute_weighted_frequencies(rand_msa, q+1,0.); c_0 = reshape(f2_0 - f1_0*f1_0', q, L, q, L\n",
    "    );f1_0 = reshape(f1_0,q,L); f2_0 = reshape(f2_0,q,L,q,L);\n",
    "\n",
    "f1,f2 = compute_weighted_frequencies(res_eq.step_msa[end], q+1,0.); c= reshape(f2 - f1*f1', q, L, q, L);\n",
    "       f1 = reshape(f1,q,L); f2 = reshape(f2,q,L,q,L);\n",
    "\n",
    "indices = partialsortperm(J[:], 1:1000, rev=true);\n",
    "\n",
    "close(\"all\"); plt.scatter(c_0[indices], c[indices]);plt.plot(\n",
    "    [minimum(c_0[indices]), maximum(c_0[indices])],[minimum(c_0[indices]), maximum(c_0[indices])]\n",
    "    ); savefig(\"../trial.png\")\n",
    "\n",
    "    \n",
    "Genie.print_fasta_to_file_rna(res_eq.step_msa[end]',\"../eq_sample_potts_t0.3_L50_d5.fa\",\"coloring\")\n",
    "@save \"../eq_sample_potts_t0.3_L50_d5.jld2\" h J \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1650a0b1-9340-404c-a2e3-71069102d12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Revise, PhyloTools, TreeTools, DCAUtils, JLD2, PyPlot, Statistics, DelimitedFiles, PottsGauge\n",
    "using AncestralSequenceReconstruction # core package\n",
    "using JLD2 # used to load ArDCA models\n",
    "using TreeTools # to handle p\n",
    "using ArDCA, KitMSA\n",
    "using Distributions\n",
    "\n",
    "L = 50; q = 4; \n",
    "\n",
    "@load \"../eq_sample_potts_t0.3_L50_d5.jld2\"; \n",
    "h_diag = h; J_diag = J;\n",
    "\n",
    "file_seqs = \"../eq_sample_potts_t0.3_L50_d5.fa\"\n",
    "\n",
    "\n",
    "\n",
    "hs = [0 .* h, h, h]; Js = [J, J, 0 .*J] ; names = [\"Only couplings\", \"Standard\", \"Profile\"];\n",
    "alphas = deepcopy(names); alpha = \"Only_couplings\"; \n",
    " \n",
    "\n",
    "\n",
    "\n",
    "eq_samples = [PhyloTools.read_rna(file_seqs,0.9) for _ in 1:3];\n",
    "\n",
    "f1, f2 = compute_weighted_frequencies(Int8.(eq_samples[1]),q+1, 0.); c= reshape(f2 - f1*f1', q, L, q, L);\n",
    "f1_0, f2_0 = compute_weighted_frequencies(Int8.(rand(1:q,L,5000)),q+1, 0.); c_0 = reshape(f2_0 - f1_0*f1_0', q, L, q, L);\n",
    "\n",
    "close(\"all\"); plt.hist(f1_0[:], histtype=\"step\", label = \"random\"); plt.hist(f1[:], histtype = \"step\",label= \"eq coloring\"\n",
    "    ); plt.xscale(\"log\"); plt.yscale(\"log\"); plt.title(\"One-point\"); plt.legend(); savefig(\"../hist1.png\")\n",
    "\n",
    "close(\"all\"); plt.hist(c_0[:], histtype=\"step\", label = \"random\"); plt.hist(c[:], histtype = \"step\",label= \"eq coloring\"\n",
    "    ); plt.xscale(\"log\"); plt.yscale(\"log\"); plt.title(\"C_ij\"); plt.legend(); savefig(\"../hist2.png\")\n",
    "\n",
    "\n",
    "start_seq = [Int.(eq_samples[i][:,1]) for i in 1:length(alphas)];\n",
    "\n",
    "ens_start = [PhyloTools.energy(start_seq[i], hs[i], Js[i]) for i in 1:length(alphas)];\n",
    "\n",
    "\n",
    "\n",
    "tree_file = \"../data_Anc/DBDtree_collapsed_noonlychild_midpointrooted_prunedsubtree301.nwk\"\n",
    "mus1 = [1., 2.,3., 4., 5.];\n",
    "#tree_file = \"../star_tree_301.nwk\"\n",
    "#mus1 = 0.33 .* [1., 2., 3., 4., 5.];\n",
    "leaves_msas = Matrix{Matrix{Int}}(undef, length(alphas), length(mus1));\n",
    "hams_leaves =  zeros(length(alphas), length(mus1));\n",
    "hams_intra_leaves = zeros(length(alphas), length(mus1));\n",
    "\n",
    "num = 1;  \n",
    "#generating data and reading it\n",
    "#for alpha in names\n",
    "    for n in 1:length(mus1) \n",
    "        @time res1 = run_evolution_ontree_amino(start_seq[num], tree_file, \n",
    "        hs[num], Js[num], mu = mus1[n], temp = 1., p = 0.5, q=q); \n",
    "        file_seqs = \"../res_algos_coloring/alpha$(alpha)_potts_mu$(round(mus1[n], \n",
    "        digits = 2)).fa\"\n",
    "        PhyloTools.leavestofasta_rna(file_seqs, res1)\n",
    "    end\n",
    "    #num += 1\n",
    "#end\n",
    "\n",
    "for n in 1:length(mus1)\n",
    "    file_seqs = \"../res_algos_coloring/alpha$(alpha)_potts_mu$(round(mus1[n], \n",
    "        digits = 2)).fa\"\n",
    "    leaves_msas[num,n] = Int.(PhyloTools.read_rna(file_seqs,0.9))\n",
    "    hams_leaves[num,n] = mean(ham_dist_nogap(start_seq[num], leaves_msas[num,n]))\n",
    "    hams_intra_leaves[num,n] = pairwise_ham_dist(leaves_msas[num,n], n_seq = 300)\n",
    "end\n",
    "\n",
    "for n in 1:length(mus1)\n",
    "    file_seqs = \"../res_algos_coloring/alpha$(alpha)_potts_mu$(round(mus1[n], \n",
    "        digits = 2)).fa\"\n",
    "    PhyloTools.convert_U_to_T_fasta(file_seqs)\n",
    "end\n",
    "\n",
    "hams_leaves\n",
    "\n",
    "\n",
    "## doing felsenstein inference\n",
    "res_ASR = zeros(Int, length(alphas), L, length(mus1));\n",
    "pp = Matrix{Matrix{Float64}}(undef, length(alphas), length(mus1));\n",
    "rec_msas = Matrix{Matrix{Int}}(undef, length(alphas), length(mus1));\n",
    "ens = Matrix{Array{Float64,1}}(undef, length(alphas), length(mus1));\n",
    "hams = Matrix{Array{Float64,1}}(undef, length(alphas), length(mus1));\n",
    "ens_ML =  zeros(length(alphas), length(mus1));\n",
    "hams_ML =  zeros(length(alphas), length(mus1));\n",
    "\n",
    "\n",
    "  \n",
    "#inference with felsenstein\n",
    "\n",
    "num = 1; #for alpha in names \n",
    "    for n in 1:length(mus1)\n",
    "        file_seqs = \"../res_algos_coloring/alpha$(alpha)_potts_mu$(round(mus1[n], \n",
    "        digits = 2)).fa\"\n",
    "        mu = infer_mu(tree_file, file_seqs)\n",
    "        ### modify this\n",
    "        res, p = PhyloTools.Felsenstein2rna(file_seqs, tree_file, file_seqs, mu)\n",
    "        res_ASR[num,:,n] .= Int.(res)\n",
    "        pp[num,n] = p\n",
    "        rec_msas[num,n] = sampling_ANC(pp[num,n], n_seq = 500)\n",
    "        hams[num,n] = ham_dist_nogap(start_seq[num], rec_msas[num,n])\n",
    "        ens[num,n] = PhyloTools.energy(rec_msas[num,n],  hs[num],  Js[num]) .- ens_start[num]\n",
    "        hams_ML[num,n] = ham_dist_nogap(start_seq[num], res_ASR[num,:,n])\n",
    "        ens_ML[num,n] = PhyloTools.energy(res_ASR[num,:,n], hs[num],  Js[num]) - ens_start[num]\n",
    "    end\n",
    "    #num +=1\n",
    "#end\n",
    "\n",
    "\n",
    "\n",
    "#learning arDCA models on equilibrium data\n",
    "\n",
    "ar_models = []\n",
    "for i in 1:length(names)\n",
    "    file_equil_seqs = \"../eq_sample_potts_t0.3_L50_d5.fa\"\n",
    "    arnet,arvar=ardca(file_equil_seqs);\n",
    "    push!(ar_models, AutoRegressiveModel(arnet))\n",
    "end\n",
    "\n",
    "#inference with arDCA\n",
    "\n",
    "res_ASR_arDCA = zeros(Int, length(alphas), L, length(mus1));\n",
    "rec_msas_arDCA = Matrix{Matrix{Int}}(undef, length(alphas), length(mus1));\n",
    "ens_arDCA = Matrix{Array{Float64,1}}(undef, length(alphas), length(mus1));\n",
    "hams_arDCA = Matrix{Array{Float64,1}}(undef, length(alphas), length(mus1));\n",
    "ens_ML_arDCA =  zeros(length(alphas), length(mus1));\n",
    "hams_ML_arDCA =  zeros(length(alphas), length(mus1));\n",
    "\n",
    "num = 1; #for alpha in names\n",
    "@time for n in 1:length(mus1)\n",
    "        fasta_file = \"../res_algos_coloring/ardca_T_alpha$(alpha)_potts_mu$(round(mus1[n], \n",
    "        digits = 2)).fa\"\n",
    "    \n",
    "        strategy = ASRMethod(;joint = false, # (default) - joint reconstruction not functional yet\n",
    "            ML = true, # (default)\n",
    "            verbosity = 1, # the default is 0. \n",
    "            optimize_branch_length = false, # (default: false) - optimize the branch lengths of the tree using the evolutionary model\n",
    "            optimize_branch_scale = false, # (default) - would optimize the branches while keeping their relative lengths fixed. Incompatible with the previous. \n",
    "            repetitions = 1, # (default) - for Bayesian reconstruction, multiple repetitions of the reconstruction process can be done to sample likely ancestors\n",
    "            );\n",
    "        opt_tree, reconstructed_sequences = infer_ancestral(\n",
    "            tree_file, fasta_file, ar_models[num], strategy\n",
    "            );\n",
    "        println(typeof(reconstructed_sequences[\"NODE_1\"]))\n",
    "        println(reconstructed_sequences[\"NODE_1\"])\n",
    "        res_ASR_arDCA[num,:,n] = PhyloTools.string2vec_rna(reconstructed_sequences[\"NODE_1\"]);\n",
    "        node_list=[\"NODE_1\"];\n",
    "        \n",
    "        \n",
    "        #this commented part is for the bayesian arDCA method\n",
    "        strategy_bayesian = ASRMethod(;\n",
    "\tjoint = false, # (default) - joint reconstruction not functional yet\n",
    "\tML = false, # (default)\n",
    "\tverbosity = 1, # the default is 0. \n",
    "\toptimize_branch_length = false, # (default: false) - optimize the branch lengths of the tree using the evolutionary model\n",
    "\toptimize_branch_scale = false, # (default) - would optimize the branches while keeping their relative lengths fixed. Incompatible with the previous. \n",
    "\trepetitions = 100,\n",
    "\n",
    ")\n",
    "        \n",
    "    file_out = \"../res_algos_coloring/ardca_inf/alpha$(alpha)_ardca_mu$(round(mus1[n],digits = 2))NODE_1.fa\";\n",
    "        infer_ancestral(\n",
    "               tree_file, fasta_file, ar_models[num], strategy_bayesian;\n",
    "               alignment_per_node=true, node_list = [\"NODE_1\"], outfasta = file_out);\n",
    "    #PhyloTools.convert_T_to_U_fasta(file_out)\n",
    "    println(n)\n",
    "    end \n",
    "    #num += 1\n",
    "#end\n",
    "\n",
    "for n in 1:length(mus1)\n",
    "    file_out = \"../res_algos_coloring/ardca_inf/alpha$(alpha)_ardca_mu$(round(mus1[n],digits = 2))NODE_1_NODE_1.fa\";\n",
    "    PhyloTools.convert_T_to_U_fasta(file_out)\n",
    "end\n",
    "    \n",
    "\n",
    "num = 1\n",
    "#for alpha in alphas\n",
    "    for n in 1:length(mus1)\n",
    "        \n",
    "        hams_ML_arDCA[num,n] = ham_dist_nogap(start_seq[num], res_ASR_arDCA[num,:,n])\n",
    "        ens_ML_arDCA[num,n] = PhyloTools.energy(res_ASR_arDCA[num,:,n], hs[num], Js[num]) - ens_start[num] \n",
    "    \n",
    "        rec_msas_arDCA[num,n] = PhyloTools.read_rna(\n",
    "        \"../res_algos_coloring/ardca_inf/ardca_U_alpha$(alpha)_ardca_mu$(round(mus1[n], digits = 2))NODE_1_NODE_1.fa\", 0.9)\n",
    "        \n",
    "        hams_arDCA[num,n] = ham_dist_nogap(start_seq[num], Int.(rec_msas_arDCA[num,n]))\n",
    "        ens_arDCA[num,n] = PhyloTools.energy(rec_msas_arDCA[num,n], hs[num], Js[num]) .- ens_start[num]\n",
    "    end\n",
    "    #num += 1\n",
    "#end\n",
    "\n",
    "\n",
    "close(\"all\")\n",
    "fig, axs = plt.subplots(figsize = (8,4))\n",
    "num = 1; #for alpha in alphas\n",
    "    axs.errorbar(hams_leaves[num,:] ./ L, [mean(hams[num,n])./L for n in 1:length(mus1)] ,\n",
    "    yerr = [std(hams[num,n])./L for n in 1:length(mus1)], \n",
    "    color = \"blue\", label = \"Felse bayes\"); \n",
    "    axs.scatter(hams_leaves[num,:] ./ L, hams_ML[num,:]./L, marker = \"X\", color = \"blue\", s = 300, label = \"Felse ML\");\n",
    "    \n",
    "    axs.errorbar(hams_leaves[num,:] ./ L, [mean(hams_arDCA[num,n])./L for n in 1:length(mus1)],\n",
    "    yerr = [std(hams_arDCA[num,n])./L for n in 1:length(mus1)], \n",
    "    color = \"red\", label = \"arDCA bayes\"); \n",
    "    axs.scatter(hams_leaves[num,:] ./ L, hams_ML_arDCA[num,:]./L, marker = \"X\", s = 300, color = \"red\", label = \"arDCA ML\");\n",
    "    axs.set_title(\"Model = $(alpha)\", fontsize = 20)\n",
    "    #num+=1\n",
    "#end\n",
    "\n",
    "fig.supxlabel(\"Leaves-root hamming\", fontsize = 20)\n",
    "axs.legend()\n",
    "axs.set_ylabel(\"Root-reconstruction \\n hamming\", fontsize = 20)\n",
    "savefig(\"../single_alpha_ham_ASR_felse_vs_arDCA.png\")\n",
    "\n",
    "\n",
    "close(\"all\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))  # Single figure, single axis\n",
    "\n",
    "# Plot Felse Bayes\n",
    "ax.errorbar(hams_intra_leaves[num, :] ./ L, [mean(hams[num, n]) / L for n in 1:length(mus1)],\n",
    "            yerr=[std(hams[num, n]) / L for n in 1:length(mus1)],\n",
    "            color=\"blue\", label=\"Felse bayes\")\n",
    "\n",
    "ax.scatter(hams_intra_leaves[num, :] ./ L, hams_ML[num, :] ./ L, marker=\"X\", color=\"blue\", s=100, label=\"Felse ML\")\n",
    "\n",
    "# Plot arDCA Bayes\n",
    "ax.errorbar(hams_intra_leaves[num, :] ./ L, [mean(hams_arDCA[num, n]) / L for n in 1:length(mus1)],\n",
    "            yerr=[std(hams_arDCA[num, n]) / L for n in 1:length(mus1)],\n",
    "            color=\"red\", label=\"arDCA bayes\")\n",
    "\n",
    "ax.scatter(hams_intra_leaves[num, :] ./ L, hams_ML_arDCA[num, :] ./ L, marker=\"X\", s=100, color=\"red\", label=\"arDCA ML\")\n",
    "\n",
    "# Labels and title\n",
    "ax.set_title(\"Model = $(alpha)\", fontsize=18)\n",
    "ax.set_xlabel(\"Leaves pairwise hamming\", fontsize=14)\n",
    "ax.set_ylabel(\"Root-reconstruction hamming\", fontsize=14)\n",
    "ax.legend()\n",
    "\n",
    "# Save the figure\n",
    "savefig(\"../single_alpha_intra_ham_ASR_felse_vs_arDCA.png\", dpi=300)\n",
    "\n",
    "\n",
    "close(\"all\")\n",
    "fig, axs = plt.subplots(figsize = (8,4) )\n",
    "num = 1; #for alpha in alphas\n",
    "    axs.errorbar(hams_leaves[num,:] ./ L, [mean(ens[num,n]) for n in 1:length(mus1)] ,\n",
    "    yerr = [std(ens[num,n])./L for n in 1:length(mus1)], \n",
    "    color = \"blue\", label = \"Felse bayes\"); \n",
    "    axs.scatter(hams_leaves[num,:] ./ L, ens_ML[num,:], marker = \"X\", color = \"blue\", s = 300, label = \"Felse ML\");\n",
    "    \n",
    "    axs.errorbar(hams_leaves[num,:] ./ L, [mean(ens_arDCA[num,n]) for n in 1:length(mus1)],\n",
    "    yerr = [std(ens_arDCA[num,n])./L for n in 1:length(mus1)], \n",
    "    color = \"red\", label = \"arDCA bayes\"); \n",
    "    axs.scatter(hams_leaves[num,:] ./ L, ens_ML_arDCA[num,:], marker = \"X\", s = 300, color = \"red\", label = \"arDCA ML\");\n",
    "    axs.set_title(\"Model = $(alpha)\", fontsize = 20)\n",
    "    #num+=1\n",
    "#end\n",
    "\n",
    "fig.supxlabel(\"Leaves-root hamming\", fontsize = 20)\n",
    "axs.legend()\n",
    "axs.set_ylabel(\"E_ASR - E_wt\", fontsize = 20)\n",
    "savefig(\"../single_alpha_en_ASR_felse_vs_arDCA.png\")\n",
    "\n",
    "\n",
    "close(\"all\")\n",
    "fig, axs = plt.subplots(figsize = (8,4) )\n",
    "num = 1; #for alpha in alphas\n",
    "    axs.errorbar(hams_intra_leaves[num,:] ./ L, [mean(ens[num,n]) for n in 1:length(mus1)] ,\n",
    "    yerr = [std(ens[num,n])./L for n in 1:length(mus1)], \n",
    "    color = \"blue\", label = \"Felse bayes\"); \n",
    "    axs.scatter(hams_intra_leaves[num,:] ./ L, ens_ML[num,:], marker = \"X\", color = \"blue\", s = 300, label = \"Felse ML\");\n",
    "    \n",
    "    axs.errorbar(hams_intra_leaves[num,:] ./ L, [mean(ens_arDCA[num,n]) for n in 1:length(mus1)],\n",
    "    yerr = [std(ens_arDCA[num,n])./L for n in 1:length(mus1)], \n",
    "    color = \"red\", label = \"arDCA bayes\"); \n",
    "    axs.scatter(hams_intra_leaves[num,:] ./ L, ens_ML_arDCA[num,:] , marker = \"X\", s = 300, color = \"red\", label = \"arDCA ML\");\n",
    "    axs.set_title(\"Model = $(alpha)\", fontsize = 20)\n",
    "    #num+=1\n",
    "#end\n",
    "fig.supxlabel(\"Leaves pairwise hamming\", fontsize = 20)\n",
    "axs.legend()\n",
    "axs.set_ylabel(\"E_ASR - E_wt\", fontsize = 20)\n",
    "savefig(\"../single_alpha_intra_en_ASR_felse_vs_arDCA.png\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.0",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
